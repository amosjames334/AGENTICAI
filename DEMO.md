# üé¨ Demo Guide

## Quick Demo (5 minutes)

This guide walks you through a complete demo of the Research Agent System.

## Prerequisites

1. Completed setup (run `./setup.sh`)
2. Added OpenAI API key to `.env`
3. Terminal ready

## Option 1: Web Interface Demo (Recommended)

### Step 1: Launch the App (30 seconds)

```bash
source venv/bin/activate
streamlit run app.py
```

Browser opens at `http://localhost:8501`

### Step 2: Enter Research Query (1 minute)

**Try one of these queries:**

```
AI for climate change prediction
```
```
Quantum computing in drug discovery
```
```
CRISPR gene editing applications
```

- Enter your query
- Set papers to 10
- Click "Search Papers"

### Step 3: Review Papers (30 seconds)

- Scroll through found papers
- Notice titles, authors, abstracts
- Papers are from arXiv's latest research

### Step 4: Start Analysis (2 minutes)

- Click "Start Agent Analysis"
- Watch progress indicator
- Wait ~2-3 minutes for completion

### Step 5: View Agent Collaboration (1 minute)

- Switch to "Agent Collaboration" tab
- See how agents worked together:
  - üîç **Researcher** analyzed the papers
  - üéØ **Critic** evaluated the findings
  - ‚ùì **Question Generator** proposed directions
  - üß© **Synthesizer** integrated insights

### Step 6: Review Results (1 minute)

- Switch to "Results" tab
- Read the Final Synthesis
- Review Follow-up Questions
- Click "Download Full Report"

**Total Time: ~5 minutes**

---

## Option 2: CLI Demo (Quick)

### One-Line Demo

```bash
python cli.py "AI for climate modeling" --max-papers 10
```

Watch the agents work:
```
[1/3] Searching arXiv for papers...
Found 10 papers
  1. Machine Learning for Climate Prediction...
  2. Deep Learning in Weather Forecasting...
  ...

[2/3] Running multi-agent analysis...
(Agents collaborating...)

[3/3] Analysis complete!
```

Results print to console!

### Save to File

```bash
python cli.py "quantum computing cryptography" \
  --max-papers 15 \
  --output my_analysis.md \
  --verbose
```

**Total Time: ~3 minutes**

---

## Example Walkthrough: Climate AI Research

### Query
```
"Machine learning for climate change prediction"
```

### Expected Output Flow

**1. Papers Found (Example)**
```
1. "Deep Learning Methods for Climate Modeling"
   Authors: Smith et al.
   Published: 2024-10

2. "Neural Networks in Weather Prediction"
   Authors: Johnson et al.
   Published: 2024-09

... (8 more)
```

**2. Researcher Agent Output**
```
üîç Research Summary

The analyzed papers reveal three main approaches to ML-based 
climate prediction:

1. **Deep Learning Architectures**: CNNs and LSTMs for 
   spatiotemporal patterns
2. **Ensemble Methods**: Combining multiple models for 
   improved accuracy
3. **Physics-Informed Neural Networks**: Integrating domain 
   knowledge

Key findings include:
- 15-20% improvement in prediction accuracy
- Reduced computational costs compared to traditional methods
- Better handling of extreme weather events

Methodologies focus on:
- Transfer learning from global to regional models
- Attention mechanisms for temporal dependencies
- Hybrid physics-ML approaches

Limitations noted:
- Data quality and availability challenges
- Interpretability concerns
- Long-term prediction uncertainty
```

**3. Critic Agent Output**
```
üéØ Critical Analysis

Strengths:
- Rigorous comparison with traditional climate models
- Large-scale validation datasets
- Clear methodological descriptions

Potential Weaknesses:
1. **Data Bias**: Most studies focus on well-monitored regions
2. **Temporal Scope**: Limited validation beyond 10-year horizons
3. **Interpretability**: Black-box nature hinders scientific insight
4. **Reproducibility**: Inconsistent reporting of hyperparameters

Missing Perspectives:
- Uncertainty quantification
- Edge cases and failure modes
- Computational resource requirements
- Ethical implications of prediction errors

Questions to Consider:
- How do these models perform in data-sparse regions?
- What happens when climate patterns shift?
- Can we trust these models for policy decisions?
```

**4. Question Generator Output**
```
‚ùì Follow-up Research Questions

1. How can we improve model interpretability while maintaining 
   prediction accuracy?

2. What hybrid approaches best combine physical climate models 
   with machine learning?

3. How do these models perform in predicting unprecedented 
   climate events?

4. What data augmentation techniques can address geographic 
   bias?

5. How can uncertainty be quantified and communicated 
   effectively?

6. What computational trade-offs exist between accuracy and 
   inference speed?

7. How can transfer learning bridge the gap between global 
   and regional predictions?
```

**5. Synthesizer Output**
```
üß© Final Synthesis

Machine learning is transforming climate prediction through 
three complementary approaches: pure deep learning, ensemble 
methods, and physics-informed networks. The research shows 
promising results with 15-20% accuracy improvements, but 
critical gaps remain.

Key Insights:
1. **Technical Progress**: Deep learning architectures, 
   especially CNNs and LSTMs, show strong pattern recognition
   
2. **Practical Challenges**: Data quality, geographic bias, 
   and interpretability limit real-world deployment

3. **Research Gaps**: Long-term validation, uncertainty 
   quantification, and edge case handling need attention

Implications:
- **For Researchers**: Focus on hybrid physics-ML approaches 
  and interpretability
- **For Practitioners**: Consider ensemble methods for robust 
  predictions
- **For Policymakers**: Use with caution, demand uncertainty 
  estimates

Future Directions:
The field is moving toward interpretable, physics-informed 
models that combine ML's pattern recognition with domain 
expertise. Success requires addressing data bias, improving 
uncertainty quantification, and validating on longer timescales.

Recommended Actions:
1. Develop standardized benchmarks for geographic diversity
2. Research interpretable architectures
3. Invest in uncertainty quantification methods
4. Create interdisciplinary collaborations

The conversation between these approaches‚Äîpure ML, physics-
informed, and ensemble methods‚Äîreveals that no single approach 
is sufficient. The future likely lies in adaptive systems that 
leverage the strengths of each while acknowledging their 
limitations.
```

---

## Demo Tips

### For Best Results

**Good Queries:**
- Specific and focused
- 3-7 words
- Clear domain
- Recent research areas

**Examples:**
- ‚úÖ "Transformer models for protein folding"
- ‚úÖ "Federated learning in healthcare"
- ‚úÖ "Quantum error correction codes"
- ‚ùå "AI" (too broad)
- ‚ùå "deep learning" (too general)

### Common Demo Questions

**Q: How long does analysis take?**
A: 2-5 minutes depending on paper count and model

**Q: Can I interrupt and resume?**
A: Not currently, but state can be saved (future feature)

**Q: How many papers is optimal?**
A: 8-12 papers gives best balance of coverage and speed

**Q: What if no papers are found?**
A: Try broader keywords or check spelling

### Impressive Demo Features

**Transparency**: Every agent's reasoning is visible

**Specialization**: Each agent has a distinct perspective

**Collaboration**: Agents build on each other's work

**Quality**: Deep, nuanced analysis beyond simple summarization

**Actionability**: Follow-up questions guide next steps

---

## Post-Demo Activities

### Try Different Topics

```bash
# Technology
python cli.py "edge computing IoT" --max-papers 10

# Science
python cli.py "CRISPR off-target effects" --max-papers 12

# Cross-disciplinary
python cli.py "AI ethics fairness" --max-papers 15
```

### Experiment with Settings

- Try different models (GPT-4 vs GPT-3.5)
- Adjust temperature (0.3 = consistent, 0.9 = creative)
- Use interactive workflow for refinement

### Export and Share

- Download reports
- Share with colleagues
- Use for literature reviews

---

## Recording Your Demo

### For Presentations

1. **Screen Recording**
   - Record the Streamlit interface
   - Show the agent collaboration flow
   - Highlight key insights

2. **Key Frames to Capture**
   - Query input
   - Paper search results
   - Agent processing (with progress)
   - Conversation flow
   - Final synthesis
   - Download report

3. **Talking Points**
   - Multiple agents collaborating
   - Transparent reasoning chain
   - Specialized perspectives
   - Actionable insights

### Demo Script (60 seconds)

```
"Let me show you how AI agents can collaborate to analyze 
research. I'll query 'AI for climate modeling' and search 
arXiv for recent papers.

[Click search]

Great, found 10 papers. Now I'll let the agents analyze these.

[Click analyze]

Watch as four specialized agents work together:
- The Researcher summarizes key findings
- The Critic evaluates limitations
- The Question Generator proposes new directions
- The Synthesizer integrates everything

[Show agent flow]

In just 3 minutes, we have a comprehensive analysis that would 
take hours manually. The agents debated, questioned, and built 
on each other's insights.

[Show synthesis]

The final synthesis gives us clear insights and actionable next 
steps. We can download this as a complete report.

This demonstrates how agents thinking together produce richer 
analysis than any single AI could alone."
```

---

## Troubleshooting Demo Issues

### "No papers found"
- Check internet connection
- Try broader keywords
- Verify arXiv is accessible

### "API Error"
- Verify API key in `.env`
- Check API quota/billing
- Try again (rate limiting)

### "Slow performance"
- Reduce paper count
- Use GPT-3.5 instead of GPT-4
- Check internet speed

### "Import errors"
- Run: `pip install -r requirements.txt`
- Verify virtual environment activated
- Run `python test_setup.py`

---

Ready to demo? üöÄ

```bash
streamlit run app.py
```

or

```bash
python cli.py "your fascinating research question"
```

**Show the world how AI agents collaborate!** üî¨‚ú®

